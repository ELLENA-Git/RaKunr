看一些音乐播放器带有音频可视化，然而现在 HTML5 也发展的如此迅速，于是我想，能不能利用 Audio API 和 Canvas 来实现音频可视化的描绘。

## 思路
为了实现音频可视化，我们得先知道 Audio API 的工作思路。
于是我在 [MDN](https://developer.mozilla.org/en-US/docs/Web/API/Web_Audio_API) 得到了下图：

![](https://hime.io/images/2015/07/08/4029390894603953.png)

通过上图，我们能知道，在声音播放到扬声器前，要经过许多效果节点，这就是我们如何实现音频可视化的关键，这篇文章当中我们需要的是 [AnalyserNode](https://developer.mozilla.org/en-US/docs/Web/API/AnalyserNode)。

## 兼容情况
Audio API 在不同的浏览器下有不同的支持情况，为了避免使用私有前缀的麻烦，我们就用下面的代码。

```javascript
window.AudioContext = window.AudioContext || window.webkitAudioContext || window.mozAudioContext || window.msAudioContext;
```

更详细的情况可移步：
Audio API: [http://caniuse.com/#feat=audio-api](http://caniuse.com/#feat=audio-api)
Canvas: [http://caniuse.com/#feat=canvas](http://caniuse.com/#feat=canvas)
RequestAnimationFrame: [http://caniuse.com/#feat=requestanimationframe](http://caniuse.com/#feat=requestanimationframe)

## 创建音频环境
```javascript
var audioContext = new window.AudioContext;
```

这个写法，没有问题。但是别忘记，AudioContext 并不支持 IE，我又不想他报错所以，加个 `try catch`

```javascript
try {
   var audioContext = new window.AudioContext;
} catch (e) {
    console.log('AudioContext does not support your browser');
}
```
## 载入音频

即使创建了音频环境，我们没有没有音频也没法渲染的，所以我们需要载入音频。

### 通过 Ajax 载入文件
通过 Ajax 载入文件需要注意 [同源策略](https://developer.mozilla.org/en-US/docs/Web/Security/Same-origin_policy) 不然会踩一个大坑。

```javascript
var request = function(url, callback) {
  var req = new XMLHttpRequest;
  
  req.open('GET', url, true);
  req.responseType = 'arraybuffer';
  req.onload = function() {
	if (typeof callback === 'function') {		
		callback(req.response);
	}
  };

  req.send();
};
```

###  通过 input 载入文件
通过监听 input 的 `onchange` 事件来实现载入文件。
完整的实现代码：

#### HTML Part
```markup
<!DOCTYPE html>
<html>
<body>
	<input type="file" id="uploadFile"></input>
	<canvas id="canvas" height="300" width="1200"></canvas>
</body>
</html>
```
#### JavaScript Part
```javascript
window.AudioContext = window.AudioContext || window.webkitAudioContext || window.mozAudioContext || window.msAudioContext;

window.requestAnimationFrame = window.requestAnimationFrame || window.webkitRequestAnimationFrame || window.mozRequestAnimationFrame || window.msRequestAnimationFrame;

var Analyser = {
  init: function() {
    // 判断是否支持 AudioContext
    try {
      this.audio = new window.AudioContext();
    } catch (e) {
      console.log('AudioContext does not support your browser');
      return false;
    }

    this.eventInit(); // 事件初始化
  },

  eventInit: function() {
    var that = this;

	that.file = new Object;
    that.audioInput = document.getElementById('uploadFile');
    that.audioCanvas = document.getElementById('canvas');

    that.audioInput.addEventListener('change', function() {
      // 防止空文件
      if (that.audioInput.files.length !== 0) {
        if (that.file.name === that.audioInput.files[0].name) return; // 为了统一 Chrome 和 Firefox 下的表现，选择同一文件是 Firefox 会做出表现，而 Chrome 并不会。
                
        that.file = that.audioInput.files[0]; // 将文件赋值到 Visualizer 对象的属性上
        that.buffer();
      }
    }, false); // 注册事件
  },

  buffer: function() {
  },

  visualizer: function(analyser) {
  }
};

Analyser.init();
```

### 通过拖拽载入文件
监听 `canvas` 的  `dragenter`  `dragover` `drop` 等事件，可实现和 input 相同的效果。

这里的代码直接对上面增加修改的部分展现

### JavaScript Part
```javascript
eventInit: function() {
...
    that.audioCanvas.addEventListener('dragover', function(e) {
      e.stopPropagation();
      e.preventDefault();
      e.dataTransfer.dropEffect = 'copy'
    }, false);

    that.audioCanvas.addEventListener('drop', function(e) {
      e.stopPropagation();
      e.preventDefault();

      if (that.file.name === e.dataTransfer.files[0].name) return;
      that.file = e.dataTransfer.files[0];
      that.buffer();
    }, false);
...
```

更多的实现方法参考：
[https://developer.mozilla.org/en-US/docs/Using_files_from_web_applications](https://developer.mozilla.org/en-US/docs/Using_files_from_web_applications)

## File to ArrayBuffer
如果直接用 Ajax 方式载入文件的话，不需要再一次的转，但是我喜欢下面两种，但 File 又不能直接用所以我们需要把 File 类转成 ArrayBuffer。所以这里我们需要用到 [FileReader](https://developer.mozilla.org/en/docs/Web/API/FileReader)。

```javascript
 buffer: function() {
    var that = this,
        reader = new FileReader(); // 新建 FileReader 对象

    // 加载完成后运行
    reader.onload = function(e) {
      var result = e.target.result,
          audio = that.audio;

      audio.decodeAudioData(result, function(buffer){
      }, function() {
        console.log('Cannot decode the file.'); // 无法解析文件
      });
    }

    reader.readAsArrayBuffer(that.file); // 解析
  }
```

## 播放声音

这样我们还不够是不是，我们得先把声音给播放出来。
为了然 `audioContext` 丰富多样，我们得先把 `buffer` 赋给 `audioContext`

```javascript
that.source = audio.createBufferSource();
that.source.buffer = buffer;
```

有了这两个东西我们就能开始播放了。

```javascript
that.source.start(0);
```

参数中的 0 表示时间，我们要从 0 开始播放。
没有声音？你还没有扬声器怎么会有声音呢。

```javascript
that.source.connect(that.audio.destination);
```

这下就有声音了吧！

## 创建分析器

我们能播放声音后，还需要一个东西来帮组我们提取数据，那就是分析器。

```javascript
var analyser = audio.createAnalyser();
```

在上面，我们是直接把 `audioBufferSouceNode` 与 `audioContext.destination` 连接在一起的，所以能直接播放到扬声器。

但是我们这里需要在播放器拦截，所以得把 `analyser` 和 `audioBufferSouceNode` 连接，再把 `analyser` 连回 `destination`

```
that.source.connect(analyser);
analyser.connect(that.audio.destination);
```

所以这里我们考虑兼容的话，整理代码会得到：

```javascript
...
reader.onload = function(e) {
      var result = e.target.result,
          audio = that.audio,
          analyser = audio.createAnalyser();

      // 如果有在播放的音频，停下他
      if (that.source) {
        if (!that.source.stop) { // 在旧的浏览器中 用 nodeOff 来代替
          that.source.nodeOff(0);
        } else {
          that.source.stop(0);
        }
      }

      audio.decodeAudioData(result, function(buffer) {
        that.source        = audio.createBufferSource();
        that.source.buffer = buffer;

        that.source.connect(analyser);
        analyser.connect(that.audio.destination);

        if (!that.source.start) { // 在旧的浏览器中 用 nodeOn 来代替
          that.source.noteOn(0);
        } else {
          that.source.start(0);
        }

        that.visualizer(analyser); // 进入下一步

      }, function() {
        console.log('Cannot decode the file.'); // 无法解析文件
      });
    }

    reader.readAsArrayBuffer(that.file); // 解析
  },
...
```

## 分析

我们通过分析器，能得到频率的能力值。

```javascript
var data = new Uint8Array(analyser.frequencyBinCount);
        analyser.getByteFrequencyData(data);
        console.log(data);
```

这个 `data` 中储存了所以从低频到高频的所有数据，用这个我们能绘成一个简单的可视图。
类似直角坐标系一样，把 Hz 当作 x 轴，能力当作 y 轴，就能有一个简单的可视图。

<figure>
<img src="//hime.io/images/2015/07/13/4439181329991226.png" />
<figcaption>简单的可视图</figcaption>
</figure>

```javascript
visualizer: function(analyser) {
    var that = this,
        canvas  = that.audioCanvas, // 获取 Canvas
        context = canvas.getContext('2d'),
        cWidth  = canvas.width, // Canvas 宽度
        cHeight = canvas.height; // Canvas 高度

    var bars = [],
        spacing  = 1, // 间距
        barWidth = 5, // 每条的宽度
        barNums  = cWidth / (barWidth + spacing); // 总共画的数量

    var gradient = context.createLinearGradient(0, 0, 0, cHeight);
        gradient.addColorStop(1, '#2FEF64');
        gradient.addColorStop(0.6, '#F4FF57');
        gradient.addColorStop(0.3, '#FFB34F');
        gradient.addColorStop(0, '#FF5B2A');

    var drawBar = function() {
      var data = new Uint8Array(analyser.frequencyBinCount);
      analyser.getByteFrequencyData(data);
      context.clearRect(0, 0, cWidth, cHeight);

      for (var i = 0; i < data.length; i++) {
        var value = data[i];

        if (bars.length < Math.round(barNums)) {
          bars.push(value);
        };

        context.fillStyle = gradient;
        context.fillRect(i, cHeight - value, 1, cHeight);
      }

      requestAnimationFrame(drawBar);
    }

    requestAnimationFrame(drawBar);
  }
```

我们的目的还没达到，因为我们需要的是实现的是那种分条的，所以我们就需要采样了。

## 采样

```javascript
    var data = new Uint8Array(analyser.frequencyBinCount);
      analyser.getByteFrequencyData(data);

    var that = this,
        canvas  = that.audioCanvas, // 获取 Canvas
        context = canvas.getContext('2d'),
        cWidth  = canvas.width, // Canvas 宽度
        cHeight = canvas.height; // Canvas 高度

    var bars = [],
        spacing  = 1, // 间距
        barWidth = 5, // 每条的宽度
        barNums  = cWidth / (barWidth + spacing),
        step = Math.round(data.length / barNums); // 总共画的数量
```

这个 `step` 就是我们需要的步长，用来采样。
然后具体的代码长这样

```javascript
  visualizer: function(analyser) {
    var data = new Uint8Array(analyser.frequencyBinCount);
      analyser.getByteFrequencyData(data);

    var that = this,
        canvas  = that.audioCanvas, // 获取 Canvas
        context = canvas.getContext('2d'),
        cWidth  = canvas.width, // Canvas 宽度
        cHeight = canvas.height; // Canvas 高度

    var bars = [],
        spacing  = 1, // 间距
        barWidth = 5, // 每条的宽度
        barNums  = cWidth / (barWidth + spacing),
        step = Math.round(data.length / barNums); // 总共画的数量

    var gradient = context.createLinearGradient(0, 0, 0, cHeight);
        gradient.addColorStop(1, '#2FEF64');
        gradient.addColorStop(0.6, '#F4FF57');
        gradient.addColorStop(0.3, '#FFB34F');
        gradient.addColorStop(0, '#FF5B2A');

    var drawBar = function() {
      var data = new Uint8Array(analyser.frequencyBinCount);
      analyser.getByteFrequencyData(data);
      var step = Math.round(data.length / barNums); //计算采样步长
      context.clearRect(0, 0, cWidth, cHeight); // 清除画布

      for (var i = 0; i < barNums; i++) {
        var value = data[i * step];
        context.fillStyle = gradient;
        context.fillRect(i * 12, cHeight - value + spacing, barWidth, cHeight);
      }

      requestAnimationFrame(drawBar);
    }

    requestAnimationFrame(drawBar);
  }
```

## 结束
播放完了怎么办呢？对 `audioBufferSouceNode` 监听 `onended` 事件就好啦。

```javascript
audioBufferSouceNode.onended = function() {
  console.log('播放完了');
}
```

然后我们就写完了，更多对能力条的自定义，自己写写？说不定有意外的收获？

```javascript
window.AudioContext = window.AudioContext || window.webkitAudioContext || window.mozAudioContext || window.msAudioContext;
  
var Analyser = {
  init: function() {
    // 判断是否支持 AudioContext
    try {
      this.audio = new window.AudioContext();
    } catch (e) {
      console.log('AudioContext does not support your browser');
      return false;
    }

    this.eventInit(); // 事件初始化
  },

  eventInit: function() {
    var that = this;

    that.file = new Object;
    that.audioInput = document.getElementById('uploadFile');
    that.audioCanvas = document.getElementById('canvas');

    that.audioInput.addEventListener('change', function() {
      // 防止空文件
      if (that.audioInput.files.length !== 0) {
        if (that.file.name === that.audioInput.files[0].name) return; // 为了统一 Chrome 和 Firefox 下的表现，选择同一文件是 Firefox 会做出表现，而 Chrome 并不会。
                
        that.file = that.audioInput.files[0]; // 将文件赋值到 Visualizer 对象的属性上
        that.buffer();
      }
    }, false); // 注册事件

    that.audioCanvas.addEventListener('dragover', function(e) {
      e.stopPropagation();
      e.preventDefault();
      e.dataTransfer.dropEffect = 'copy';
    }, false);

    that.audioCanvas.addEventListener('drop', function(e) {
      e.stopPropagation();
      e.preventDefault();

      if (that.file.name === e.dataTransfer.files[0].name) return;
      that.file = e.dataTransfer.files[0];
      that.buffer();
    }, false);
  },

  buffer: function() {
    var that = this,
        reader = new FileReader(); // 新建 FileReader 对象

    // 加载完成后运行
    reader.onload = function(e) {
      var result = e.target.result,
          audio = that.audio,
          analyser = audio.createAnalyser();

      // 如果有在播放的音频，停下他
      if (that.source) {
        if (!that.source.stop) { // 在旧的浏览器中 用 nodeOff 来代替
          that.source.nodeOff(0);
        } else {
          that.source.stop(0);
        }
      }

      audio.decodeAudioData(result, function(buffer) {
        that.source        = audio.createBufferSource();
        that.source.buffer = buffer;

        that.source.connect(analyser);
        analyser.connect(that.audio.destination);

        if (!that.source.start) { // 在旧的浏览器中 用 nodeOn 来代替
          that.source.noteOn(0);
        } else {
          that.source.start(0);
        }

        that.source.onended = function() {
          console.log('播放完了');
        }

        that.visualizer(analyser); // 进入下一步

      }, function() {
        console.log('Cannot decode the file.'); // 无法解析文件
      });
    }

    reader.readAsArrayBuffer(that.file); // 解析
  },

  visualizer: function(analyser) {
    var data = new Uint8Array(analyser.frequencyBinCount);
      analyser.getByteFrequencyData(data);

    var that = this,
        canvas  = that.audioCanvas, // 获取 Canvas
        context = canvas.getContext('2d'),
        cWidth  = canvas.width, // Canvas 宽度
        cHeight = canvas.height; // Canvas 高度

    var bars = [],
        spacing  = 1, // 间距
        barWidth = 5, // 每条的宽度
        barNums  = cWidth / (barWidth + spacing),
        step = Math.round(data.length / barNums); // 总共画的数量

    var gradient = context.createLinearGradient(0, 0, 0, cHeight);
        gradient.addColorStop(1, '#2FEF64');
        gradient.addColorStop(0.6, '#F4FF57');
        gradient.addColorStop(0.3, '#FFB34F');
        gradient.addColorStop(0, '#FF5B2A');

    var drawBar = function() {
      var data = new Uint8Array(analyser.frequencyBinCount);
      analyser.getByteFrequencyData(data);
      var step = Math.round(data.length / barNums); //计算采样步长
      context.clearRect(0, 0, cWidth, cHeight); // 清除画布

      for (var i = 0; i < barNums; i++) {
        var value = data[i * step];
        context.fillStyle = gradient;
        context.fillRect(i * 12, cHeight - value + spacing, barWidth, cHeight);
      }

      requestAnimationFrame(drawBar);
    }

    requestAnimationFrame(drawBar);
  }
};

Analyser.init();
```

这是完整的代码。

## 参考资料

1. https://developer.mozilla.org/en-US/docs/Web/API/Web_Audio_API
2. https://developer.mozilla.org/en-US/docs/Using_files_from_web_applications
3. https://developer.mozilla.org/en/docs/Web/API/FileReader
4. https://developer.mozilla.org/en-US/docs/Web/API/AnalyserNode
5. http://cbrandolino.github.io/local-audio-visualizer/docs/local_audio_visualizer
6. http://wayou.github.io/HTML5_Audio_Visualizer/js/html5_audio_visualizer.js